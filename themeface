#!/usr/bin/env python2

import face_recognition
import getopt
import glob
import os.path
import signal
import sys
from sys import stdout as out
from threading import Timer
from timeit import default_timer as now
import time

from pprint import pprint as pp

opts, args = getopt.getopt(sys.argv[1:],
        "vc:r:f:l:%:p:",
        ["camera=", "rotate=", "fps=", "detect-length=", "detect-percentage=", "music="])
show_video = False
camera_index = None
rotation = 0
fps = 10
detect_length = 1.0
detect_percentage = 0.75
music_path = "music"
for opt, arg in opts:
    if opt == "-v":
        show_video = True
    elif opt in ["-c", "--camera"]:
        camera_index = int(arg)
    elif opt in ["-r", "--rotate"]:
        rotation = int(arg)
    elif opt in ["-f", "--fps"]:
        fps = int(arg)
    elif opt in ["-l", "--detect-length"]:
        detect_length = float(arg)
    elif opt in ["-%", "--detect-percentage="]:
        detect_percentage = float(arg) / 100.0
    elif opt in ["-p", "--music-path"]:
        music_path = arg

print("-> Starting Camera... ")
print("Attempting to run at {}fps".format(fps))
try:
    import camera.pi as camera
    have_opencv = False
    print("Raspberry Pi Camera")
except:
    try:
        import camera.opencv as camera
        import cv2
        have_opencv = True
        print("Webcam via OpenCV")
    except ImportError:
        print("Cannot load any camera. Exiting.")
        exit(2)

if rotation != 0:
    print("Rotating image {} degrees clockwise.".format(rotation))

if camera_index is None:
    print("Default camera.")
    camera_index = 0
else:
    print("Camera index {}.".format(camera_index))

camera = camera.Camera((320, 240), camera_index=camera_index)
print("Done.")

if show_video and not have_opencv:
    print("Unable to show video output.")

print("-> Loading training data... ")
source_files = glob.glob("source_images/*.*")
names = []
source_encodings = []
for filename in source_files:
    print(filename)
    image = face_recognition.load_image_file(filename)
    encoding = face_recognition.face_encodings(image)[0]
    names.append(os.path.basename(filename).split(".")[0])
    source_encodings.append(encoding)

print("Done.")
# Initialize some variables
face_locations = []
face_encodings = []
face_names = []
detections = {}
frame_length = 1.0 / fps

# No, globals aren't the best, but neither is this script!
processing = True
def signal_handler(signal, frame):
    global processing
    processing = False
signal.signal(signal.SIGINT, signal_handler)

def play(name):
    if os.fork() == 0:
        files = glob.glob(os.path.join(music_path, name + ".*"))
        if len(files) > 0:
            os.execvp("afplay", ("afplay", files[0]))
        else:
            os.execvp("say", ("say", "-v", "Tessa", "this is the theme music for", name))

def unhold(name):
    def unhold_person():
        detections.pop(name, None)
    return unhold_person

def detect_entrance_for(name):
    def detect_entrance():
        required_amount = fps * detect_length * detect_percentage
        print("\n{}: {}/{} in {}s".format(name, detections[name], required_amount, detect_length))
        if detections[name] >= required_amount:
            print("PLAYING")
            play(name)
            detections[name] = "hold"
        else:
            print ("QUIET")
        Timer(600, unhold(name))
    return detect_entrance

print("-> Processing video... ")
while processing:
    start_time = now()

    # Grab a single frame of video
    frame = camera.capture_frame()

    if rotation > 0:
        frame = camera.rotate(frame, rotation=rotation)

    # Find all the faces and face encodings in the current frame of video
    face_locations = face_recognition.face_locations(frame)
    face_encodings = face_recognition.face_encodings(frame, face_locations)

    face_names = []
    for face_encoding in face_encodings:
        matches = face_recognition.compare_faces(source_encodings, face_encoding)
        face_names = face_names + [name for name, match in zip(names, matches) if match]

    matches = len(face_locations)
    if matches > 0:
        for name in face_names:
            if name not in detections:
                timer = Timer(detect_length, detect_entrance_for(name))
                timer.start()
                detections[name] = 1
            elif detections[name] == "hold":
                "Ignore this."
            else:
                detections[name] = detections[name] + 1

    if show_video and have_opencv:
        for (top, right, bottom, left), name in zip(face_locations, face_names):
            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)
            font = cv2.FONT_HERSHEY_DUPLEX
            cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)

        cv2.imshow('Video', frame)
        cv2.waitKey(1)

    processing_time = now() - start_time
    out.write("\r\33[2K")
    out.write("Found {} face".format(matches))
    if matches == 1:
        out.write(": ")
    elif matches > 0:
        out.write("s: ")
    else:
        out.write("s")
    out.write(", ".join(sorted(face_names)))
    out.write(" in {0:.2f}s.".format(processing_time))
    out.flush()

    # Wait for FPS
    if processing_time < frame_length:
        time.sleep(frame_length - processing_time)

camera.release()
if have_opencv:
    cv2.destroyAllWindows()
print("\nDone.")
